rag:
  name: "huggingface_rag"
  description: "RAG pipeline using Hugging Face models"
  
  # Document processing
  chunk_size: 1000
  chunk_overlap: 200
  text_splitter_type: "recursive"
  
  # Vector store configuration
  vector_store_type: "chroma"
  embedding_model: "text-embedding-ada-002"
  persist_directory: "./data/vectorstore"
  
  # LLM configuration
  llm_provider: "huggingface"
  llm_model: "meta-llama/Llama-2-7b-chat-hf"
  llm_api_key: null  # Set via HUGGINGFACE_API_KEY environment variable
  llm_task: "text-generation"  # or "conversational"
  temperature: 0.1
  max_tokens: 1000
  
  # Retrieval configuration
  top_k: 4
  similarity_threshold: 0.7
  
  # Memory configuration
  memory_enabled: true
  memory_type: "in_memory"
  
  # Streaming configuration
  streaming_enabled: false
  
  # Additional metadata
  metadata:
    version: "1.0.0"
    environment: "production"
    tags: ["rag", "huggingface", "llama"] 