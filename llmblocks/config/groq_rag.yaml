rag:
  name: "groq_rag"
  description: "RAG pipeline using Groq models"
  
  # Document processing
  chunk_size: 1000
  chunk_overlap: 200
  text_splitter_type: "recursive"
  
  # Vector store configuration
  vector_store_type: "chroma"
  embedding_model: "text-embedding-ada-002"
  persist_directory: "./data/vectorstore"
  
  # LLM configuration
  llm_provider: "groq"
  llm_model: "llama3-8b-8192"
  llm_api_key: null  # Set via GROQ_API_KEY environment variable
  temperature: 0.1
  max_tokens: 1000
  
  # Retrieval configuration
  top_k: 4
  similarity_threshold: 0.7
  
  # Memory configuration
  memory_enabled: true
  memory_type: "in_memory"
  
  # Streaming configuration
  streaming_enabled: false
  
  # Additional metadata
  metadata:
    version: "1.0.0"
    environment: "production"
    tags: ["rag", "groq", "llama3"] 